{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "import csv\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL CLEANUP\n",
    "def url_fix(s, charset='utf-8'):\n",
    "    if isinstance(s, unicode):\n",
    "        s = s.encode(charset, 'ignore')\n",
    "    scheme, netloc, path, qs, anchor = urlparse.urlsplit(s)\n",
    "    path = urllib.quote(path, '/%')\n",
    "    qs = urllib.quote_plus(qs, ':&=')\n",
    "    return urlparse.urlunsplit((scheme, netloc, path, qs, anchor))\n",
    "\n",
    "\n",
    "# COMMAND PARSER\n",
    "def tw_parser():\n",
    "    global qw, ge, l, t, c, d\n",
    "\n",
    "    # USE EXAMPLES:\n",
    "    # =-=-=-=-=-=-=\n",
    "    # % twsearch <search term>            --- searches term\n",
    "    # % twsearch <search term> -g sf      --- searches term in SF geographic box <DEFAULT = none>\n",
    "    # % twsearch <search term> -l en      --- searches term with lang=en (English) <DEFAULT = en>\n",
    "    # % twsearch <search term> -t {m,r,p} --- searches term of type: mixed, recent, or popular <DEFAULT = recent>\n",
    "    # % twsearch <search term> -c 12      --- searches term and returns 12 tweets (count=12) <DEFAULT = 1>\n",
    "    # % twsearch <search term> -o {ca, tx, id, co, rtc)   --- searches term and sets output options <DEFAULT = ca, tx>\n",
    "\n",
    "    # Parse the command\n",
    "    parser = argparse.ArgumentParser(description='Twitter Search')\n",
    "    parser.add_argument(action='store', dest='query', help='Search term string')\n",
    "    parser.add_argument('-g', action='store', dest='loca', help='Location (lo, nyl, nym, nyu, dc, sf, nb')\n",
    "    parser.add_argument('-l', action='store', dest='l', help='Language (en = English, fr = French, etc...)')\n",
    "    parser.add_argument('-t', action='store', dest='t', help='Search type: mixed, recent, or popular')\n",
    "    parser.add_argument('-c', action='store', dest='c', help='Tweet count (must be <50)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    qw = args.query  # Actual query word(s)\n",
    "    ge = ''\n",
    "\n",
    "    # Location\n",
    "    loca = args.loca\n",
    "    if (not (loca in ('lo', 'nyl', 'nym', 'nyu', 'dc', 'sf', 'nb')) and (loca)):\n",
    "        print(\"WARNING: Location must be one of these: lo, nyl, nym, nyu, dc, sf, nb\")\n",
    "        exit()\n",
    "    if loca:\n",
    "        ge = locords[loca]\n",
    "\n",
    "    # Language\n",
    "    l = args.l\n",
    "    if (not l):\n",
    "        l = \"en\"\n",
    "    if (not (l in ('en', 'fr', 'es', 'po', 'ko', 'ar'))):\n",
    "        print(\n",
    "            \"WARNING: Languages currently supported are: en (English), fr (French), es (Spanish), po (Portuguese), ko (Korean), ar (Arabic)\")\n",
    "        exit()\n",
    "\n",
    "    # Tweet type\n",
    "    t = args.t\n",
    "    if (not t):\n",
    "        t = \"recent\"\n",
    "    if (not (t in ('mixed', 'recent', 'popular'))):\n",
    "        print(\"WARNING: Search type must be one of: (m)ixed, (r)ecent, or (p)opular\")\n",
    "        exit()\n",
    "\n",
    "    # Tweet count\n",
    "    if args.c:\n",
    "        c = int(args.c)\n",
    "        if (c > cmax):\n",
    "            print(\"Resetting count to \", cmax, \" (maximum allowed)\")\n",
    "            c = cmax\n",
    "        if (not (c) or (c < 1)):\n",
    "            c = 1\n",
    "    if not (args.c):\n",
    "        c = 1\n",
    "\n",
    "    print(\"Query: %s, Location: %s, Language: %s, Search type: %s, Count: %s\" % (qw, ge, l, t, c))\n",
    "\n",
    "\n",
    "# AUTHENTICATION (OAuth)\n",
    "def tw_oauth(authfile):\n",
    "    with open(authfile, \"r\") as f:\n",
    "        ak = f.readlines()\n",
    "    f.close()\n",
    "    auth1 = tweepy.auth.OAuthHandler(ak[0].replace(\"\\n\", \"\"), ak[1].replace(\"\\n\", \"\"))\n",
    "    auth1.set_access_token(ak[2].replace(\"\\n\", \"\"), ak[3].replace(\"\\n\", \"\"))\n",
    "    return tweepy.API(auth1)\n",
    "\n",
    "\n",
    "def tw_search_json(query, cnt=5):\n",
    "    authfile = './auth.k'\n",
    "    api = tw_oauth(authfile)\n",
    "    results = {}\n",
    "    meta = {\n",
    "        'username': 'text',\n",
    "        'usersince': 'date',\n",
    "        'followers': 'numeric',\n",
    "        'friends': 'numeric',\n",
    "        'authorid': 'text',\n",
    "        'authorloc': 'geo',\n",
    "        'geoenable': 'boolean',\n",
    "        'source': 'text'\n",
    "    }\n",
    "    data = []\n",
    "    for tweet in tweepy.Cursor(api.search, q=query, count=cnt).items():\n",
    "        dTwt = {}\n",
    "        dTwt['username'] = tweet.author.name\n",
    "        dTwt['usersince'] = tweet.author.created_at  # author/user profile creation date\n",
    "        dTwt['followers'] = tweet.author.followers_count  # number of author/user followers (inlink)\n",
    "        dTwt['friends'] = tweet.author.friends_count  # number of author/user friends (outlink)\n",
    "        dTwt['authorid'] = tweet.author.id  # author/user ID#\n",
    "        dTwt['authorloc'] = tweet.author.location  # author/user location\n",
    "        dTwt['geoenable'] = tweet.author.geo_enabled  # is author/user account geo enabled?\n",
    "        dTwt['source'] = tweet.source  # platform source for tweet\n",
    "        data.append(dTwt)\n",
    "    results['meta'] = meta\n",
    "    results['data'] = data\n",
    "    return results\n",
    "\n",
    "\n",
    "# TWEEPY SEARCH FUNCTION\n",
    "def tw_search(api):\n",
    "    counter = 0\n",
    "    # Open/Create a file to append data\n",
    "    csvFile = open('result.csv', 'w')\n",
    "    # Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow([\"created\", \"text\", \"retwc\", \"hashtag\", \"followers\", \"friends\"])\n",
    "\n",
    "    for tweet in tweepy.Cursor(api.search,\n",
    "                               q=qw,\n",
    "                               g=ge,\n",
    "                               lang=l,\n",
    "                               result_type=t,\n",
    "                               count=c).items():\n",
    "\n",
    "        # TWEET INFO\n",
    "        created = tweet.created_at  # tweet created\n",
    "        text = tweet.text  # tweet text\n",
    "        tweet_id = tweet.id  # tweet ID# (not author ID#)\n",
    "        cords = tweet.coordinates  # geographic co-ordinates\n",
    "        retwc = tweet.retweet_count  # re-tweet count\n",
    "        try:\n",
    "            hashtag = tweet.entities[u'hashtags'][0][u'text']  # hashtags used\n",
    "        except:\n",
    "            hashtag = \"None\"\n",
    "        try:\n",
    "            rawurl = tweet.entities[u'urls'][0][u'url']  # URLs used\n",
    "            urls = url_fix(rawurl)\n",
    "        except:\n",
    "            urls = \"None\"\n",
    "        # AUTHOR INFO\n",
    "        username = tweet.author.name  # author/user name\n",
    "        usersince = tweet.author.created_at  # author/user profile creation date\n",
    "        followers = tweet.author.followers_count  # number of author/user followers (inlink)\n",
    "        friends = tweet.author.friends_count  # number of author/user friends (outlink)\n",
    "        authorid = tweet.author.id  # author/user ID#\n",
    "        authorloc = tweet.author.location  # author/user location\n",
    "        # TECHNOLOGY INFO\n",
    "        geoenable = tweet.author.geo_enabled  # is author/user account geo enabled?\n",
    "        source = tweet.source  # platform source for tweet\n",
    "        # Dongho 03/28/16\n",
    "        csvWriter.writerow([created, str(text).encode(\"utf-8\"), retwc, hashtag, followers, friends])\n",
    "        counter = counter + 1\n",
    "        if (counter == c):\n",
    "            break\n",
    "\n",
    "    csvFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN ROUTINE\n",
    "def main():\n",
    "    global api, cmax, locords\n",
    "\n",
    "    # Geo-coordinates of five metropolitan areas\n",
    "    # London, NYC (lower, middle, upper), Wash DC, San Francisco, New Brunswick (NJ)\n",
    "    locords = {'lo': '0, 51.503, 20km',\n",
    "               'nyl': '-74, 40.73, 2mi',\n",
    "               'nym': '-74, 40.74, 2mi',\n",
    "               'nyu': '-73.96, 40.78, 2mi',\n",
    "               'dc': '-77.04, 38.91, 2mi',\n",
    "               'sf': '-122.45, 37.74, 5km',\n",
    "               'nb': '-74.45, 40.49, 2mi'}\n",
    "    # Maximum allowed tweet count (note: Twitter sets this to ~180 per 15 minutes)\n",
    "    cmax = 50\n",
    "    # OAuth key file\n",
    "    authfile = './auth.k'\n",
    "\n",
    "    tw_parser()\n",
    "    api = tw_oauth(authfile)\n",
    "    tw_search(api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-g LOCA] [-l L] [-t T] [-c C] query\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daveyap/anaconda3/envs/new_env_for_imblearn/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
